# MINT: Multi-Agent Interactive Reinforcement Learning for Trajectory Generation


### Abstract
Trajectory Generation Models (TGM), which utilize intelligent agents to model human mobility behaviors and generate synthetic yet realistic trajectories, provide valuable solutions to the challenge of insufficient trajectory data in in many real-world applications, such as urban planning, epidemic spreading analysis, and geographic privacy protect. Previous works usually adopt single-agent framework to implement TGM, where urban environment is over simplified and information exchange among agents are ignored. In this paper we propose a multi-agent interactive reinforcement learning-based trajectory generation model, namely MINT, to overcome this limitation. The MINT model considers the trajectory generation as a partially observable Markov decision process. The trajectory generator (agent) is a deep sequential model capable of encoding not only its own local information but also the states of observable surrounding agents. This design enables effective information exchange among agents during the trajectory generation process. Moreover, we employ a multi-agent actor-critic algorithm to train the agent from both micro and macro levels. At the micro level, the reward function and the critic network work together to ensure that the generated trajectories progress towards their respective destinations. At the macro level, the algorithm ensures that the trajectories generated by all agents are consistent with the overall similarity of the real trajectories. Extensive experiments and two practical applications on three real-world trajectory datasets to demonstrate the effectiveness and robustness of our proposed method. To the best of our knowledge, this is the first effort on construct TGM from a multi-agent information exchange perspective. 

### Dataset

The `BJ_Taxi` collected by us is open-source at [BaiduDisk with code p9u5](https://pan.baidu.com/s/1WNwIg52DbIbx1sIxB9WT1A?pwd=p9u5).

For the `Chengdu` and `Xian`, it is obtained from DIDI GAIA project, so we cannot provide the data directly.